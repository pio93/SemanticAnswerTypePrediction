{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_dataset.evaluation.dbpedia.evaluate import evaluate, load_ground_truth, load_system_output, load_type_hierarchy\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading type hierarchy from ./smart_dataset/evaluation/dbpedia/dbpedia_types.tsv... 761 types loaded (max depth: 7)\n"
     ]
    }
   ],
   "source": [
    "# Import the type-centric baseline results\n",
    "type_hier = load_type_hierarchy('./smart_dataset/evaluation/dbpedia/dbpedia_types.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From ground truth:\n",
    "# (\"What is the name of the opera based on Twelfth Night ?\", \"dbo:Opera\", 1)\n",
    "# (\"What is the name of the opera based on Twelfth Night ?\", \"dbo:MusicalWork\", 1)\n",
    "# (\"What is the name of the opera based on Twelfth Night ?\", \"dbo:Work\", 1)\n",
    "# From type centric baseline results\n",
    "# {\"id\": \"dbpedia_14427\", \"question\": \"What is the name of the opera based on Twelfth Night ?\", \"category\": \"resource\", \"type\": [\"dbo:Album\", \"dbo:Sound\", \"dbo:Song\", \"dbo:Book\", \"dbo:TelevisionEpisode\"]}\n",
    "# (\"What is the name of the opera based on Twelfth Night ?\", \"dbo:Album\", 0)\n",
    "# (\"What is the name of the opera based on Twelfth Night ?\", \"dbo:Song\", 0)\n",
    "# (\"What is the name of the opera based on Twelfth Night ?\", \"dbo:Sound\", 0) <- 0 as long as not on same branch\n",
    "\n",
    "# make one BOW sparse matrix for questions, and one for types, concatenate them horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dbpedia_1177</td>\n",
       "      <td>Was Jacqueline Kennedy Onassis a follower of M...</td>\n",
       "      <td>boolean</td>\n",
       "      <td>[boolean]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dbpedia_14427</td>\n",
       "      <td>What is the name of the opera based on Twelfth...</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Opera, dbo:MusicalWork, dbo:Work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dbpedia_16615</td>\n",
       "      <td>When did Lena Horne receive the Grammy Award f...</td>\n",
       "      <td>literal</td>\n",
       "      <td>[date]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dbpedia_23480</td>\n",
       "      <td>Do Prince Harry and Prince William have the sa...</td>\n",
       "      <td>boolean</td>\n",
       "      <td>[boolean]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dbpedia_3681</td>\n",
       "      <td>What is the subsidiary company working for Leo...</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:EducationalInstitution, dbo:Organisation,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17566</th>\n",
       "      <td>dbpedia_7462</td>\n",
       "      <td>Is the flexural strain at break of the acrylon...</td>\n",
       "      <td>boolean</td>\n",
       "      <td>[boolean]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17567</th>\n",
       "      <td>dbpedia_17610</td>\n",
       "      <td>Where did Hilary Putnam receive their Ph.D.?</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:University, dbo:EducationalInstitution, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17568</th>\n",
       "      <td>dbpedia_505</td>\n",
       "      <td>Who replaced Charles Evans Hughes as the Chief...</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Person, dbo:Agent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17569</th>\n",
       "      <td>dbpedia_18989</td>\n",
       "      <td>Name the river with source as Columbia Lake an...</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:River, dbo:Stream, dbo:BodyOfWater, dbo:N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17570</th>\n",
       "      <td>dbpedia_11517</td>\n",
       "      <td>When will Selma Lagerlöf start their membershi...</td>\n",
       "      <td>literal</td>\n",
       "      <td>[date]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17528 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                           question  \\\n",
       "0       dbpedia_1177  Was Jacqueline Kennedy Onassis a follower of M...   \n",
       "1      dbpedia_14427  What is the name of the opera based on Twelfth...   \n",
       "2      dbpedia_16615  When did Lena Horne receive the Grammy Award f...   \n",
       "3      dbpedia_23480  Do Prince Harry and Prince William have the sa...   \n",
       "4       dbpedia_3681  What is the subsidiary company working for Leo...   \n",
       "...              ...                                                ...   \n",
       "17566   dbpedia_7462  Is the flexural strain at break of the acrylon...   \n",
       "17567  dbpedia_17610       Where did Hilary Putnam receive their Ph.D.?   \n",
       "17568    dbpedia_505  Who replaced Charles Evans Hughes as the Chief...   \n",
       "17569  dbpedia_18989  Name the river with source as Columbia Lake an...   \n",
       "17570  dbpedia_11517  When will Selma Lagerlöf start their membershi...   \n",
       "\n",
       "       category                                               type  \n",
       "0       boolean                                          [boolean]  \n",
       "1      resource             [dbo:Opera, dbo:MusicalWork, dbo:Work]  \n",
       "2       literal                                             [date]  \n",
       "3       boolean                                          [boolean]  \n",
       "4      resource  [dbo:EducationalInstitution, dbo:Organisation,...  \n",
       "...         ...                                                ...  \n",
       "17566   boolean                                          [boolean]  \n",
       "17567  resource  [dbo:University, dbo:EducationalInstitution, d...  \n",
       "17568  resource                            [dbo:Person, dbo:Agent]  \n",
       "17569  resource  [dbo:River, dbo:Stream, dbo:BodyOfWater, dbo:N...  \n",
       "17570   literal                                             [date]  \n",
       "\n",
       "[17528 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the SMART task training data\n",
    "train_filename = './data/smarttask_dbpedia_train.json'\n",
    "df = pd.read_json(train_filename).dropna(subset=['question', 'type'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the DBpedia ontology provided by the SMART task return a list containing the types \n",
    "# AND their parents that are in the input type list\n",
    "def expand_with_parents(type_hierarchy: dict, dbo_types: list) -> list:\n",
    "    # take a list of dbpedia types and expand it to include the types' parents\n",
    "    type_set = set(dbo_types)\n",
    "    for typ in dbo_types:\n",
    "        if typ not in type_hierarchy.keys():\n",
    "            type_set.add(typ)\n",
    "            continue\n",
    "\n",
    "        typ2=typ\n",
    "        while type_hierarchy[typ2]['parent'] != 'owl:Thing':\n",
    "            typ2 =  type_hierarchy[typ2]['parent']\n",
    "            type_set.add(typ2)\n",
    "    return list(type_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dbpedia_14427</td>\n",
       "      <td>What is the name of the opera based on Twelfth...</td>\n",
       "      <td>resource</td>\n",
       "      <td>dbo:Work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dbpedia_14427</td>\n",
       "      <td>What is the name of the opera based on Twelfth...</td>\n",
       "      <td>resource</td>\n",
       "      <td>dbo:MusicalWork</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dbpedia_14427</td>\n",
       "      <td>What is the name of the opera based on Twelfth...</td>\n",
       "      <td>resource</td>\n",
       "      <td>dbo:Opera</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dbpedia_3681</td>\n",
       "      <td>What is the subsidiary company working for Leo...</td>\n",
       "      <td>resource</td>\n",
       "      <td>dbo:Agent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dbpedia_3681</td>\n",
       "      <td>What is the subsidiary company working for Leo...</td>\n",
       "      <td>resource</td>\n",
       "      <td>dbo:EducationalInstitution</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17569</th>\n",
       "      <td>dbpedia_18989</td>\n",
       "      <td>Name the river with source as Columbia Lake an...</td>\n",
       "      <td>resource</td>\n",
       "      <td>dbo:River</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17569</th>\n",
       "      <td>dbpedia_18989</td>\n",
       "      <td>Name the river with source as Columbia Lake an...</td>\n",
       "      <td>resource</td>\n",
       "      <td>dbo:NaturalPlace</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17569</th>\n",
       "      <td>dbpedia_18989</td>\n",
       "      <td>Name the river with source as Columbia Lake an...</td>\n",
       "      <td>resource</td>\n",
       "      <td>dbo:Location</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17569</th>\n",
       "      <td>dbpedia_18989</td>\n",
       "      <td>Name the river with source as Columbia Lake an...</td>\n",
       "      <td>resource</td>\n",
       "      <td>dbo:BodyOfWater</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17569</th>\n",
       "      <td>dbpedia_18989</td>\n",
       "      <td>Name the river with source as Columbia Lake an...</td>\n",
       "      <td>resource</td>\n",
       "      <td>dbo:Stream</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28230 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                           question  \\\n",
       "1      dbpedia_14427  What is the name of the opera based on Twelfth...   \n",
       "1      dbpedia_14427  What is the name of the opera based on Twelfth...   \n",
       "1      dbpedia_14427  What is the name of the opera based on Twelfth...   \n",
       "4       dbpedia_3681  What is the subsidiary company working for Leo...   \n",
       "4       dbpedia_3681  What is the subsidiary company working for Leo...   \n",
       "...              ...                                                ...   \n",
       "17569  dbpedia_18989  Name the river with source as Columbia Lake an...   \n",
       "17569  dbpedia_18989  Name the river with source as Columbia Lake an...   \n",
       "17569  dbpedia_18989  Name the river with source as Columbia Lake an...   \n",
       "17569  dbpedia_18989  Name the river with source as Columbia Lake an...   \n",
       "17569  dbpedia_18989  Name the river with source as Columbia Lake an...   \n",
       "\n",
       "       category                        type  relevance  \n",
       "1      resource                    dbo:Work          1  \n",
       "1      resource             dbo:MusicalWork          1  \n",
       "1      resource                   dbo:Opera          1  \n",
       "4      resource                   dbo:Agent          1  \n",
       "4      resource  dbo:EducationalInstitution          1  \n",
       "...         ...                         ...        ...  \n",
       "17569  resource                   dbo:River          1  \n",
       "17569  resource            dbo:NaturalPlace          1  \n",
       "17569  resource                dbo:Location          1  \n",
       "17569  resource             dbo:BodyOfWater          1  \n",
       "17569  resource                  dbo:Stream          1  \n",
       "\n",
       "[28230 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a training set using the ground truth from the train set as binary relevant results\n",
    "df_train = df[df['category'] == 'resource'].copy()\n",
    "df_train['type'] = df_train['type'].apply(lambda x: expand_with_parents(type_hier[0], x))\n",
    "df_train = df_train.explode('type').dropna(subset=['type'])\n",
    "df_train['relevance'] = 1\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading system predictions from ./data/baseline_TC_results_train.json... \n",
      "   17297 predictions loaded\n",
      "Loading system predictions from ./data/baseline_EC_results_train.json... \n",
      "   17254 predictions loaded\n"
     ]
    }
   ],
   "source": [
    "# Get negative training records from baseline system output types (ones that don't also appear in ground truth)\n",
    "system_outputs = {'TC': load_system_output('./data/baseline_TC_results_train.json'), 'EC': load_system_output('./data/baseline_EC_results_train.json')}\n",
    "neg_lst_tc = list()\n",
    "neg_lst_ec = list()\n",
    "for system, so in system_outputs.items():\n",
    "    for key, values in so.items():\n",
    "        if values['category'] == 'resource' and len(values['type']) > 0:\n",
    "            system_types = values['type']\n",
    "            system_types = expand_with_parents(type_hier[0], system_types)\n",
    "            gt_types = df[df['id'] == key]['type'].tolist()[0]\n",
    "            question = df[df['id'] == key]['question'].tolist()[0]\n",
    "            neg_types = list(set(system_types).difference(set(gt_types)))\n",
    "            for neg_type in neg_types:\n",
    "                if system == 'TC':\n",
    "                    neg_lst_tc.append({'id': key, 'question': question, 'category': 'resource', 'type':neg_type, 'relevance':0})\n",
    "                elif system == 'EC':\n",
    "                    neg_lst_ec.append({'id': key, 'question': question, 'category': 'resource', 'type':neg_type, 'relevance':0})\n",
    "df_train_tc = pd.concat([df_train, pd.DataFrame(neg_lst_tc)])\n",
    "df_train_ec = pd.concat([df_train, pd.DataFrame(neg_lst_ec)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113897, 13020) (82700, 13020)\n"
     ]
    }
   ],
   "source": [
    "# obtain sparse matrices for the BOW representations of the questions\n",
    "count_vec_tc = CountVectorizer()\n",
    "x_train_tc = count_vec_tc.fit_transform(df_train_tc['question'])\n",
    "count_vec_ec = CountVectorizer()\n",
    "x_train_ec = count_vec_ec.fit_transform(df_train_ec['question'])\n",
    "print(x_train_tc.shape, x_train_ec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113897, 466) (82700, 473)\n"
     ]
    }
   ],
   "source": [
    "# obtain sparse matrices for the types of the training records\n",
    "count_vec_types_tc = CountVectorizer()\n",
    "count_vec_types_ec = CountVectorizer()\n",
    "x_train_types_tc = count_vec_types_tc.fit_transform(df_train_tc['type'])\n",
    "x_train_types_ec = count_vec_types_ec.fit_transform(df_train_ec['type'])\n",
    "print(x_train_types_tc.shape, x_train_types_ec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113897, 13486) (82700, 13493)\n"
     ]
    }
   ],
   "source": [
    "# combine to a single query-type training vector\n",
    "x_train_ec = hstack([x_train_ec, x_train_types_ec])\n",
    "x_train_tc = hstack([x_train_tc, x_train_types_tc])\n",
    "print(x_train_tc.shape, x_train_ec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate logistic regression relevance classifiers\n",
    "clf_ec = LogisticRegression(random_state=0, solver='saga', max_iter=1000).fit(x_train_ec, df_train_ec['relevance'].to_list())\n",
    "clf_tc = LogisticRegression(random_state=0, solver='saga', max_iter=1000).fit(x_train_tc, df_train_tc['relevance'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate random forest relevance classifiers\n",
    "rfm_ec = RandomForestClassifier(n_jobs=10).fit(x_train_ec, df_train_ec['relevance'].to_list())\n",
    "rfm_tc = RandomForestClassifier(n_jobs=10).fit(x_train_tc, df_train_tc['relevance'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate naive bayes relevance classifiers\n",
    "mnb_ec = MultinomialNB().fit(x_train_ec, df_train_ec['relevance'].to_list())\n",
    "mnb_tc = MultinomialNB().fit(x_train_tc, df_train_tc['relevance'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading system predictions from ./data/baseline_TC_results_test.json... \n",
      "   4369 predictions loaded\n",
      "Loading system predictions from ./data/baseline_EC_results_test.json... \n",
      "   4369 predictions loaded\n"
     ]
    }
   ],
   "source": [
    "# go through the baseline results one by one, expand types to include the parents, add any types above threshold to replacement types\n",
    "system_outputs = {'TC': load_system_output('./data/baseline_TC_results_test.json'), 'EC': load_system_output('./data/baseline_EC_results_test.json')}\n",
    "test_questions = pd.read_json(open('./data/smarttask_dbpedia_test_questions.json'))\n",
    "for system, so in system_outputs.items():\n",
    "    ltr_so_lr = list() # logistic regression\n",
    "    ltr_so_rf = list() # random forest\n",
    "    ltr_so_nb = list() # naive bayes\n",
    "    for key, values in so.items():\n",
    "        question = test_questions[test_questions['id'] == key]['question'].tolist()[0]\n",
    "        new_types_lr = set()\n",
    "        new_types_rf = set()\n",
    "        new_types_nb = set()\n",
    "        if values['category'] == 'resource':\n",
    "            types = values['type']\n",
    "            for typ in expand_with_parents(type_hier[0], types):\n",
    "                if system == 'TC':\n",
    "                    query_doc_vec = hstack([count_vec_tc.transform([question]), count_vec_types_tc.transform([typ])])\n",
    "                    proba = clf_tc.predict_proba(query_doc_vec)[0][1]\n",
    "                    if proba > 0.01:\n",
    "                        new_types_lr.add(typ)\n",
    "                    rf_result = rfm_tc.predict_proba(query_doc_vec)[0][1]\n",
    "                    if rf_result > 0.2:\n",
    "                        new_types_rf.add(typ)\n",
    "                    nb_result = mnb_tc.predict_proba(query_doc_vec)[0][1]\n",
    "                    if nb_result > 0.2:\n",
    "                        new_types_nb.add(typ)\n",
    "                elif system == 'EC':\n",
    "                    try:\n",
    "                        query_doc_vec = hstack([count_vec_ec.transform([question]), count_vec_types_ec.transform([typ])])\n",
    "                    except NotFittedError:\n",
    "                        continue\n",
    "                    proba = clf_ec.predict_proba(query_doc_vec)[0][1]\n",
    "                    if proba > 0.01:\n",
    "                        new_types_lr.add(typ)\n",
    "                    rf_result = rfm_ec.predict_proba(query_doc_vec)[0][1]\n",
    "                    if rf_result > 0.2:\n",
    "                        new_types_rf.add(typ)\n",
    "                    nb_result = mnb_ec.predict_proba(query_doc_vec)[0][1]\n",
    "                    if nb_result > 0.2:\n",
    "                        new_types_nb.add(typ)\n",
    "        ltr_so_lr.append({'id': key, 'question': question, 'category': values['category'], 'type': list(new_types_lr) if len(new_types_lr) > 0 else values['type'] })\n",
    "        ltr_so_rf.append({'id': key, 'question': question, 'category': values['category'], 'type': list(new_types_rf) if len(new_types_rf) > 0 else values['type'] })\n",
    "        ltr_so_nb.append({'id': key, 'question': question, 'category': values['category'], 'type': list(new_types_nb) if len(new_types_rf) > 0 else values['type'] })\n",
    "\n",
    "    with open('./data/baseline_' + system + '_results_test_ltr_lr.json', 'w') as outfile:\n",
    "        json.dump(ltr_so_lr, outfile)\n",
    "    with open('./data/baseline_' + system + '_results_test_ltr_rf.json', 'w') as outfile:\n",
    "        json.dump(ltr_so_rf, outfile)\n",
    "    with open('./data/baseline_' + system + '_results_test_ltr_nb.json', 'w') as outfile:\n",
    "        json.dump(ltr_so_nb, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ground truth from ./data/smarttask_dbpedia_test.json... \n",
      "   4369 questions loaded\n",
      "Loading system predictions from ./data/baseline_TC_results_test_ltr_lr.json... \n",
      "   4369 predictions loaded\n",
      "TYPE CENTRIC\n",
      "\n",
      "\n",
      "Evaluation results:\n",
      "-------------------\n",
      "Category prediction (based on 4369 questions)\n",
      "  Accuracy: 0.939\n",
      "Type ranking (based on 4369 questions)\n",
      "  NDCG@5:  0.526\n",
      "  NDCG@10: 0.539\n",
      "Loading system predictions from ./data/baseline_EC_results_test_ltr_lr.json... \n",
      "   4369 predictions loaded\n",
      "ENTITY CENTRIC\n",
      "\n",
      "\n",
      "Evaluation results:\n",
      "-------------------\n",
      "Category prediction (based on 4369 questions)\n",
      "  Accuracy: 0.939\n",
      "Type ranking (based on 4369 questions)\n",
      "  NDCG@5:  0.550\n",
      "  NDCG@10: 0.546\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION RESULTS\n",
    "gt = load_ground_truth('./data/smarttask_dbpedia_test.json', type_hier[0].keys())\n",
    "so = load_system_output('./data/baseline_TC_results_test_ltr_lr.json')\n",
    "print('TYPE CENTRIC')\n",
    "evaluate(so, gt, type_hier[0], 7)\n",
    "\n",
    "so = load_system_output('./data/baseline_EC_results_test_ltr_lr.json')\n",
    "print('ENTITY CENTRIC')\n",
    "evaluate(so, gt, type_hier[0], 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ground truth from ./data/smarttask_dbpedia_test.json... \n",
      "   4369 questions loaded\n",
      "Loading system predictions from ./data/baseline_TC_results_test_ltr_rf.json... \n",
      "   4369 predictions loaded\n",
      "TYPE CENTRIC\n",
      "\n",
      "\n",
      "Evaluation results:\n",
      "-------------------\n",
      "Category prediction (based on 4369 questions)\n",
      "  Accuracy: 0.939\n",
      "Type ranking (based on 4369 questions)\n",
      "  NDCG@5:  0.576\n",
      "  NDCG@10: 0.552\n",
      "Loading system predictions from ./data/baseline_EC_results_test_ltr_rf.json... \n",
      "   4369 predictions loaded\n",
      "ENTITY CENTRIC\n",
      "\n",
      "\n",
      "Evaluation results:\n",
      "-------------------\n",
      "Category prediction (based on 4369 questions)\n",
      "  Accuracy: 0.939\n",
      "Type ranking (based on 4369 questions)\n",
      "  NDCG@5:  0.571\n",
      "  NDCG@10: 0.552\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST RESULTS\n",
    "gt = load_ground_truth('./data/smarttask_dbpedia_test.json', type_hier[0].keys())\n",
    "so = load_system_output('./data/baseline_TC_results_test_ltr_rf.json')\n",
    "print('TYPE CENTRIC')\n",
    "evaluate(so, gt, type_hier[0], 7)\n",
    "\n",
    "so = load_system_output('./data/baseline_EC_results_test_ltr_rf.json')\n",
    "print('ENTITY CENTRIC')\n",
    "evaluate(so, gt, type_hier[0], 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ground truth from ./data/smarttask_dbpedia_test.json... \n",
      "   4369 questions loaded\n",
      "Loading system predictions from ./data/baseline_TC_results_test_ltr_nb.json... \n",
      "   4369 predictions loaded\n",
      "TYPE CENTRIC\n",
      "\n",
      "\n",
      "Evaluation results:\n",
      "-------------------\n",
      "Category prediction (based on 4369 questions)\n",
      "  Accuracy: 0.939\n",
      "Type ranking (based on 4369 questions)\n",
      "  NDCG@5:  0.516\n",
      "  NDCG@10: 0.500\n",
      "Loading system predictions from ./data/baseline_EC_results_test_ltr_nb.json... \n",
      "   4369 predictions loaded\n",
      "ENTITY CENTRIC\n",
      "\n",
      "\n",
      "Evaluation results:\n",
      "-------------------\n",
      "Category prediction (based on 4369 questions)\n",
      "  Accuracy: 0.939\n",
      "Type ranking (based on 4369 questions)\n",
      "  NDCG@5:  0.537\n",
      "  NDCG@10: 0.521\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES RESULTS\n",
    "gt = load_ground_truth('./data/smarttask_dbpedia_test.json', type_hier[0].keys())\n",
    "so = load_system_output('./data/baseline_TC_results_test_ltr_nb.json')\n",
    "print('TYPE CENTRIC')\n",
    "evaluate(so, gt, type_hier[0], 7)\n",
    "\n",
    "so = load_system_output('./data/baseline_EC_results_test_ltr_nb.json')\n",
    "print('ENTITY CENTRIC')\n",
    "evaluate(so, gt, type_hier[0], 7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DAT640')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c43aba33fda91952d5a2011b59e45f5bc4f87c2a3dae86255c1f22beb51a9e24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
